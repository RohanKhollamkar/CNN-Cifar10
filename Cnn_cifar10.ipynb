{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN on Cifar 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation, GlobalAveragePooling2D, AveragePooling2D\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The data is in pickle file, to unpickle it we define following function\n",
    "def unpickle(file):\n",
    "    with open(file,'rb') as f:\n",
    "        dict_file = pickle.load(f, encoding='latin1')\n",
    "    return dict_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unpickle train and test batches.\n",
    "## Get Images and their labels \n",
    "def load_data(folder_path):\n",
    "    label_names = unpickle(folder_path + \"\\\\batches.meta\")['label_names']\n",
    "    test_data = unpickle(folder_path + \"\\\\test_batch\")['data']\n",
    "    test_labels = np.asarray(unpickle(folder_path + \"\\\\test_batch\")['labels'])\n",
    "     \n",
    "    data, labels = [], []\n",
    "    for i in range(1,6):\n",
    "        batch = unpickle(file= folder_path + \"\\\\data_batch_\" + str(i))\n",
    "        if len(data) == 0:\n",
    "            data = batch['data']\n",
    "            labels = batch['labels']         \n",
    "        else:\n",
    "            data = np.vstack((data, batch['data']))\n",
    "            labels = np.hstack((labels, batch['labels']))   \n",
    "                        \n",
    "        \n",
    "    return data, labels, label_names,test_data, test_labels\n",
    "\n",
    "train_data, train_labels, label_names, test_data, test_labels = load_data(folder_path=\"D:\\Convolutional Neural Networks and Computer Vision\\cifar-10-batches-py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode labels\n",
    "def one_hot(label):\n",
    "    category = np.zeros((len(label), 10))\n",
    "    for num, i in enumerate(label):\n",
    "        category[num][i] = 1\n",
    "    return category    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for preprocessing image before feeding them algorithm\n",
    "def preprocess_imgs(train, test, train_labs, test_labs):\n",
    "    # Reshape Images in train and test data\n",
    "    train_data = train.reshape(train.shape[0],3,32,32).transpose(0,2,3,1).astype('uint8')\n",
    "    test_data = test.reshape(test.shape[0],3,32,32).transpose(0,2,3,1).astype('uint8')\n",
    "    \n",
    "    # Scale the image data\n",
    "    train_data = train_data/ 255\n",
    "    test_data  = test_data/ 255\n",
    "    \n",
    "    # Encode the labels\n",
    "    train_labels = one_hot(train_labs)\n",
    "    test_labels = one_hot(test_labs)\n",
    "    \n",
    "    return train_data, test_data, train_labels, test_labels\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = preprocess_imgs(train_data, test_data, train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:  (50000, 32, 32, 3)\n",
      "Shape of testing data:  (10000, 32, 32, 3)\n",
      "Shape of train labels:  (50000, 10)\n",
      "Shape of test labels:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training data: \", train_data.shape)\n",
    "print(\"Shape of testing data: \", test_data.shape)\n",
    "print(\"Shape of train labels: \", train_labels.shape)\n",
    "print(\"Shape of test labels: \", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now that we have loaded the dataset and preprocessed them,  Images are ready for an algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32,32,3)))    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))    \n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 30, 30, 64)        36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,297,866\n",
      "Trainable params: 1,297,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss calculation and weight optimization for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', ##crossentropy for classification\n",
    "              optimizer=Adam(lr=0.0001), ## learning rate with 1.0e-4\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('Cnn_Cifar10.h5',  # model filename\n",
    "                             monitor='val_loss', # Validation loss to monitor\n",
    "                             verbose=0,\n",
    "                             save_best_only= True, # Saves best model only\n",
    "                             mode='auto') # Automatically decides to save the best model based on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 1.8950 - acc: 0.3021 - val_loss: 1.5924 - val_acc: 0.4200\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 1.5793 - acc: 0.4254 - val_loss: 1.4429 - val_acc: 0.4717\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 1.4525 - acc: 0.4742 - val_loss: 1.3446 - val_acc: 0.5175\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 1.3664 - acc: 0.5090 - val_loss: 1.2663 - val_acc: 0.5430\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 1.3064 - acc: 0.5310 - val_loss: 1.2542 - val_acc: 0.5539\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 1.2579 - acc: 0.5537 - val_loss: 1.1823 - val_acc: 0.5775\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 1.2099 - acc: 0.5695 - val_loss: 1.1593 - val_acc: 0.5808\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 1.1725 - acc: 0.5834 - val_loss: 1.0988 - val_acc: 0.6124\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 1.1409 - acc: 0.5952 - val_loss: 1.0785 - val_acc: 0.6185\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 1.1102 - acc: 0.6069 - val_loss: 1.0364 - val_acc: 0.6360\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 1.0797 - acc: 0.6171 - val_loss: 1.0136 - val_acc: 0.6431\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 1.0600 - acc: 0.6251 - val_loss: 0.9910 - val_acc: 0.6562\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 1.0331 - acc: 0.6363 - val_loss: 0.9791 - val_acc: 0.6573\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 153s 3ms/step - loss: 1.0095 - acc: 0.6453 - val_loss: 0.9533 - val_acc: 0.6653\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.9865 - acc: 0.6533 - val_loss: 0.9401 - val_acc: 0.6733\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.9680 - acc: 0.6613 - val_loss: 0.9428 - val_acc: 0.6688\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.9529 - acc: 0.6649 - val_loss: 0.9222 - val_acc: 0.6783\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 158s 3ms/step - loss: 0.9325 - acc: 0.6745 - val_loss: 0.8983 - val_acc: 0.6875\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 158s 3ms/step - loss: 0.9149 - acc: 0.6787 - val_loss: 0.8832 - val_acc: 0.6910\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 160s 3ms/step - loss: 0.8958 - acc: 0.6837 - val_loss: 0.8732 - val_acc: 0.6947\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 158s 3ms/step - loss: 0.8821 - acc: 0.6903 - val_loss: 0.8633 - val_acc: 0.7018\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.8683 - acc: 0.6952 - val_loss: 0.8518 - val_acc: 0.7046\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.8563 - acc: 0.7006 - val_loss: 0.8587 - val_acc: 0.6984\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.8416 - acc: 0.7058 - val_loss: 0.8321 - val_acc: 0.7111\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.8255 - acc: 0.7125 - val_loss: 0.8254 - val_acc: 0.7124\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.8124 - acc: 0.7141 - val_loss: 0.8216 - val_acc: 0.7132\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.7990 - acc: 0.7205 - val_loss: 0.8141 - val_acc: 0.7148\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.7818 - acc: 0.7259 - val_loss: 0.8038 - val_acc: 0.7197\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.7746 - acc: 0.7287 - val_loss: 0.7896 - val_acc: 0.7262\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.7599 - acc: 0.7324 - val_loss: 0.7951 - val_acc: 0.7239\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.7470 - acc: 0.7378 - val_loss: 0.7859 - val_acc: 0.7266\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.7376 - acc: 0.7414 - val_loss: 0.7853 - val_acc: 0.7226\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.7259 - acc: 0.7453 - val_loss: 0.7664 - val_acc: 0.7346\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.7111 - acc: 0.7504 - val_loss: 0.7751 - val_acc: 0.7274\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.7005 - acc: 0.7554 - val_loss: 0.7739 - val_acc: 0.7276\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.6878 - acc: 0.7601 - val_loss: 0.7705 - val_acc: 0.7321\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.6828 - acc: 0.7612 - val_loss: 0.7635 - val_acc: 0.7312\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.6740 - acc: 0.7664 - val_loss: 0.7632 - val_acc: 0.7329\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.6633 - acc: 0.7682 - val_loss: 0.7464 - val_acc: 0.7391\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.6498 - acc: 0.7709 - val_loss: 0.7373 - val_acc: 0.7435\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 158s 3ms/step - loss: 0.6415 - acc: 0.7768 - val_loss: 0.7433 - val_acc: 0.7417\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.6318 - acc: 0.7781 - val_loss: 0.7391 - val_acc: 0.7409\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.6258 - acc: 0.7816 - val_loss: 0.7307 - val_acc: 0.7439\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.6126 - acc: 0.7827 - val_loss: 0.7312 - val_acc: 0.7427\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.6011 - acc: 0.7888 - val_loss: 0.7349 - val_acc: 0.7448\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.5945 - acc: 0.7904 - val_loss: 0.7523 - val_acc: 0.7396\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.5847 - acc: 0.7936 - val_loss: 0.7225 - val_acc: 0.7477\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 158s 3ms/step - loss: 0.5769 - acc: 0.7984 - val_loss: 0.7147 - val_acc: 0.7513\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.5625 - acc: 0.8011 - val_loss: 0.7151 - val_acc: 0.7514\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.5573 - acc: 0.8024 - val_loss: 0.7163 - val_acc: 0.7523\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.5471 - acc: 0.8085 - val_loss: 0.7185 - val_acc: 0.7519\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.5373 - acc: 0.8118 - val_loss: 0.7126 - val_acc: 0.7524\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.5367 - acc: 0.8091 - val_loss: 0.7071 - val_acc: 0.7533\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.5256 - acc: 0.8142 - val_loss: 0.7027 - val_acc: 0.7552\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.5157 - acc: 0.8189 - val_loss: 0.7119 - val_acc: 0.7535\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.5048 - acc: 0.8219 - val_loss: 0.7039 - val_acc: 0.7571\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.5054 - acc: 0.8220 - val_loss: 0.7074 - val_acc: 0.7575\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.4946 - acc: 0.8221 - val_loss: 0.6989 - val_acc: 0.7587\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.4906 - acc: 0.8254 - val_loss: 0.7006 - val_acc: 0.7591\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.4826 - acc: 0.8297 - val_loss: 0.7115 - val_acc: 0.7596\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.4672 - acc: 0.8355 - val_loss: 0.7199 - val_acc: 0.7597\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.4664 - acc: 0.8359 - val_loss: 0.7171 - val_acc: 0.7547\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 0.4544 - acc: 0.8379 - val_loss: 0.7021 - val_acc: 0.7605\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 160s 3ms/step - loss: 0.4468 - acc: 0.8397 - val_loss: 0.6983 - val_acc: 0.7657\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 0.4443 - acc: 0.8405 - val_loss: 0.6905 - val_acc: 0.7656\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.4412 - acc: 0.8434 - val_loss: 0.6956 - val_acc: 0.7631\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.4228 - acc: 0.8482 - val_loss: 0.7057 - val_acc: 0.7654\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.4254 - acc: 0.8484 - val_loss: 0.6956 - val_acc: 0.7640\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.4189 - acc: 0.8511 - val_loss: 0.6991 - val_acc: 0.7649\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 0.4133 - acc: 0.8519 - val_loss: 0.7017 - val_acc: 0.7643\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 0.4047 - acc: 0.8549 - val_loss: 0.7069 - val_acc: 0.7616\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 158s 3ms/step - loss: 0.3982 - acc: 0.8586 - val_loss: 0.7067 - val_acc: 0.7655\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 0.3896 - acc: 0.8616 - val_loss: 0.7036 - val_acc: 0.7684\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 0.3901 - acc: 0.8618 - val_loss: 0.7063 - val_acc: 0.7665\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 160s 3ms/step - loss: 0.3806 - acc: 0.8640 - val_loss: 0.7156 - val_acc: 0.7639\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 0.3806 - acc: 0.8650 - val_loss: 0.7180 - val_acc: 0.7669\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 161s 3ms/step - loss: 0.3719 - acc: 0.8670 - val_loss: 0.7086 - val_acc: 0.7693\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 158s 3ms/step - loss: 0.3662 - acc: 0.8695 - val_loss: 0.7089 - val_acc: 0.7684\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 160s 3ms/step - loss: 0.3645 - acc: 0.8687 - val_loss: 0.7043 - val_acc: 0.7670\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 0.3600 - acc: 0.8720 - val_loss: 0.7075 - val_acc: 0.7694\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 0.3582 - acc: 0.8721 - val_loss: 0.7193 - val_acc: 0.7656\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 165s 3ms/step - loss: 0.3474 - acc: 0.8775 - val_loss: 0.7154 - val_acc: 0.7676\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 161s 3ms/step - loss: 0.3450 - acc: 0.8788 - val_loss: 0.7071 - val_acc: 0.7701\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 0.3396 - acc: 0.8779 - val_loss: 0.7081 - val_acc: 0.7693\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 0.3322 - acc: 0.8804 - val_loss: 0.7149 - val_acc: 0.7702\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 0.3326 - acc: 0.8816 - val_loss: 0.7200 - val_acc: 0.7691\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 0.3283 - acc: 0.8816 - val_loss: 0.7229 - val_acc: 0.7675\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 171s 3ms/step - loss: 0.3217 - acc: 0.8852 - val_loss: 0.7199 - val_acc: 0.7696\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 167s 3ms/step - loss: 0.3154 - acc: 0.8863 - val_loss: 0.7148 - val_acc: 0.7721\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 172s 3ms/step - loss: 0.3147 - acc: 0.8854 - val_loss: 0.7159 - val_acc: 0.7708\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 0.3124 - acc: 0.8882 - val_loss: 0.7122 - val_acc: 0.7736\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 0.3021 - acc: 0.8924 - val_loss: 0.7211 - val_acc: 0.7711\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 0.3033 - acc: 0.8906 - val_loss: 0.7221 - val_acc: 0.7714\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 167s 3ms/step - loss: 0.2979 - acc: 0.8936 - val_loss: 0.7235 - val_acc: 0.7719\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 167s 3ms/step - loss: 0.2967 - acc: 0.8933 - val_loss: 0.7250 - val_acc: 0.7707\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 165s 3ms/step - loss: 0.2888 - acc: 0.8961 - val_loss: 0.7386 - val_acc: 0.7727\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 0.2848 - acc: 0.8994 - val_loss: 0.7302 - val_acc: 0.7724\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 0.2833 - acc: 0.8984 - val_loss: 0.7400 - val_acc: 0.7742\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 161s 3ms/step - loss: 0.2784 - acc: 0.8985 - val_loss: 0.7422 - val_acc: 0.7741\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 161s 3ms/step - loss: 0.2775 - acc: 0.9007 - val_loss: 0.7525 - val_acc: 0.7691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c6867bbf60>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,batch_size = 128, epochs = 100, \n",
    "          validation_data= (test_data, test_labels),verbose=1,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating learned parameters on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 15s 1ms/step\n",
      "Test Accuracy:  76.91%\n"
     ]
    }
   ],
   "source": [
    "test_score = model.evaluate(test_data,test_labels)\n",
    "print(\"Test Accuracy: \", str(test_score[1] *100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
